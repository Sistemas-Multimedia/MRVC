{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWT (Discrete Wavelet Transform)\n",
    "\n",
    "How to compress images using the DWT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "%matplotlib inline\n",
    "import image\n",
    "import DWT\n",
    "import pywt\n",
    "import distortion\n",
    "import YCoCg as YUV\n",
    "import deadzone as Q\n",
    "import math\n",
    "import information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet = pywt.Wavelet(\"Haar\")\n",
    "#wavelet = pywt.Wavelet(\"db1\")\n",
    "#wavelet = pywt.Wavelet(\"db5\")\n",
    "wavelet = pywt.Wavelet(\"bior3.1\")\n",
    "#wavelet = pywt.Wavelet(\"bior3.3\")\n",
    "print(wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = \"../sequences/lena_color/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_levels = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_steps = [128, 64, 32, 16, 8, 4, 2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First ... some handy routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(prefix):\n",
    "    x = image.read(prefix, 0)\n",
    "    if len(x.shape) == 2:\n",
    "        extended_x = np.zeros(shape=(x.shape[0],  x.shape[1], 3), dtype=np.uint16) \n",
    "        extended_x[..., 0] = x\n",
    "        return extended_x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def write_compact_decomposition(decom, prefix, image_number):\n",
    "    rows = decom[len(decom)-1][0].shape[0]*2\n",
    "    cols = decom[len(decom)-1][0].shape[1]*2\n",
    "    coms = decom[0].shape[2]\n",
    "    image_shape = (rows, cols, coms)\n",
    "    view = np.empty(image_shape, np.uint16)\n",
    "    # LL subband\n",
    "    view[0:decom[0].shape[0],\n",
    "         0:decom[0].shape[1]] = (decom[0].astype(np.int32) + 32768).astype(np.uint16)\n",
    "\n",
    "    for l in range(len(decom)-1):\n",
    "\n",
    "        # LH\n",
    "        view[0:decom[l+1][0].shape[0],\n",
    "             decom[l+1][0].shape[1]:decom[l+1][0].shape[1]*2] =\\\n",
    "                (decom[l+1][0].astype(np.int32) + 32768).astype(np.uint16)\n",
    "\n",
    "        # HL\n",
    "        view[decom[l+1][1].shape[0]:decom[l+1][1].shape[0]*2,\n",
    "             0:decom[l+1][1].shape[1]] =\\\n",
    "                (decom[l+1][1].astype(np.int32) + 32768).astype(np.uint16)\n",
    "\n",
    "        # HH\n",
    "        view[decom[l+1][2].shape[0]:decom[l+1][2].shape[0]*2,\n",
    "             decom[l+1][2].shape[1]:decom[l+1][2].shape[1]*2] =\\\n",
    "                (decom[l+1][2].astype(np.int32) + 32768).astype(np.uint16)\n",
    "            \n",
    "    return image.write(view, prefix, image_number)\n",
    "    \n",
    "def read_compact_decomposition(prefix, image_number, N_levels):\n",
    "    view = image.read(prefix, image_number)\n",
    "    wavelet = pywt.Wavelet(\"Haar\")\n",
    "    decom = DWT.analyze(np.zeros_like(view), wavelet, N_levels)\n",
    "    \n",
    "    # LL subband\n",
    "    decom[0][...] = view[0:decom[0].shape[0],\n",
    "                         0:decom[0].shape[1]] - 32768\n",
    "    \n",
    "    for l in range(len(N_levels)):\n",
    "        \n",
    "        # LH\n",
    "        decom[l+1][0] =\\\n",
    "            view[0:decom[l+1][0].shape[0],\n",
    "                 decom[l+1][0].shape[1]:decom[l+1][0].shape[1]*2] - 32668\n",
    "            \n",
    "        # HL\n",
    "        decom[l+1][1] =\\\n",
    "            view[decom[l+1][1].shape[0]:decom[l+1][1].shape[0]*2,\n",
    "                 0:decom[l+1][1].shape[1]] - 32768\n",
    "            \n",
    "        # HH\n",
    "        decom[l+1][2] =\\\n",
    "            view[decom[l+1][2].shape[0]:decom[l+1][2].shape[0]*2,\n",
    "                 decom[l+1][2].shape[1]:decom[l+1][2].shape[1]*2] - 32768\n",
    "\n",
    "    return decom\n",
    "\n",
    "def entropy(decomposition):\n",
    "    entro = information.entropy(decomposition[0].flatten().astype(np.int16))\n",
    "    accumulated_entropy = entro * decomposition[0].size\n",
    "    image_size = decomposition[0].size\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            entro = information.entropy(sb.flatten().astype(np.int16))\n",
    "            accumulated_entropy += (entro * sb.size)\n",
    "            image_size += sb.size\n",
    "    avg_entropy = accumulated_entropy / image_size\n",
    "    return avg_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `DWT.analyze_step()` and `DCT.synthesize_step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_image(test_image)\n",
    "image.show_RGB_image(x, title=\"Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, H = DWT.analyze_step(x, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show_RGB_image(255*image.normalize(L), \"LL DWT domain\")\n",
    "subbands = (\"LH\", \"HL\", \"HH\")\n",
    "for i, sb in enumerate(subbands):\n",
    "    image.show_RGB_image(255*image.normalize(H[i]), f\"{sb} DWT domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = DWT.synthesize_step(L, H, wavelet).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = x - z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show_RGB_image(255*image.normalize(r), f\"DWT finite precission error N_DWT_levels={N_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DWT is not fully reversible, but it is almost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show_RGB_image(z, \"Reconstructed image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `DWT.analyze()` and `DCT.synthesize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "z = DWT.synthesize(y, wavelet, N_levels).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = x - z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.max(), r.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show_RGB_image(255*image.normalize(r), f\"DWT finite precission error N_DWT_levels={N_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion.MSE(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show_RGB_image(z, \"Reconstructed image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subbands information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_image(test_image).astype(np.int16) - 128\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "print(\"sb maximum mininum average std-dev entropy        energy  avg-enegy\")\n",
    "entro = information.entropy(y[0].flatten().astype(np.int16))\n",
    "accumulated_entropy = entro * y[0].size\n",
    "print(f\" 0 {y[0].max():7.1f} {y[0].min():7.1f} {np.average(y[0]):7.1f} {math.sqrt(np.var(y[0])):7.1f} {entro:7.1f} {information.energy(y[0]):13.1f} {information.energy(y[0])/y[0].size:10.1f}\")\n",
    "sb_index = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        entro = information.entropy(sb.flatten().astype(np.int16))\n",
    "        accumulated_entropy += (entro * sb.size)\n",
    "        print(f\"{sb_index:2d} {sb.max():7.1f} {sb.min():7.1f} {np.average(sb):7.1f} {math.sqrt(np.var(sb)):7.1f} {entro:7.1f} {information.energy(sb):13.1f} {information.energy(sb)/sb.size:10.1f}\")\n",
    "        sb_index += 1\n",
    "avg_entropy = accumulated_entropy / x.size\n",
    "print(\"Average entropy in the wavelet domain:\", avg_entropy)\n",
    "print(\"Entropy in the image domain:\", information.entropy(x.flatten().astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, most of the energy (and information) is concentrated in the low-frequency subbands. It's also worth to realize that the high-frequency subbands are potentially more compressibles. Finally, the wavelet domain is potentially more compressible than the image domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD performance using \"constant\" quantization among subbands\n",
    "\n",
    "We compute the RD cuve of using uniform quantization in the wavelet domain, for different quantization steps. To measure the distortion we have two alternatives:\n",
    "1. Always considering that the transform is (bi)orthogonal and therefore, the distortion among subbands is uncorrelated, we can measure the quantization error in the wavelet domain, inside of the quantized subband, considering the inverse transform gain of such subband.\n",
    "2. We can measure the distortion in the image domain, after inversely transforming the quantized decomposition. Obviously, this alternative is slower. However, this is the only choice is the transform is not (bi)orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = read_image(test_image)\n",
    "x = YUV.from_RGB(xx.astype(np.int16) - 128)\n",
    "\n",
    "DWT_points = []\n",
    "for Q_step in Q_steps:\n",
    "    y = DWT.analyze(x, wavelet, N_levels)\n",
    "    y_k = []\n",
    "    y_dQ = []\n",
    "    LL = y[0]\n",
    "    LL_k = Q.quantize(LL, Q_step)\n",
    "    LL_dQ = Q.dequantize(LL_k, Q_step)\n",
    "    y_k.append(LL_k)\n",
    "    y_dQ.append(LL_dQ)\n",
    "    #dist = distortion.MSE(LL, LL_dQ)\n",
    "    #MSE = (dist * LL.size)/x.size\n",
    "    #print(gains[0], dist, gains[0] * dist, MSE)\n",
    "    #for i in range(4):\n",
    "    #    for j in range(4):\n",
    "    #        print(LL[i, j], LL_dQ[i, j])\n",
    "    for sr in y[1:]:\n",
    "        sr_k = []\n",
    "        sr_dQ = []\n",
    "        for sb in sr:\n",
    "            #print(MSE)\n",
    "            sb_k = Q.quantize(sb, Q_step)\n",
    "            sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "            sr_k.append(sb_k)\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            #dist = distortion.MSE(sb, sb_dQ)\n",
    "            #print(gains[counter], dist, gains[counter] * dist, MSE)\n",
    "            #MSE += (dist * sb.size)/x.size\n",
    "        y_k.append(tuple(sr_k))\n",
    "        y_dQ.append(tuple(sr_dQ))\n",
    "    BPP = (write_compact_decomposition(y_k, f\"/tmp/constant_{Q_step}_\", 0)*8)/x.size\n",
    "    z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "    zz_dQ = np.clip(YUV.to_RGB(z_dQ), a_min=-128, a_max=127) + 128\n",
    "    MSE = distortion.MSE(xx, zz_dQ)\n",
    "    print(f\"{Q_step} {BPP} {MSE}\")\n",
    "    DWT_points.append((BPP, MSE))\n",
    "    image.show_RGB_image(zz_dQ, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT_points = []\n",
    "with open(\"DCT.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        rate, _distortion = line.split('\\t')\n",
    "        DCT_points.append((float(rate), float(_distortion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DCT_points), label=f\"DCT optimal Q\")\n",
    "pylab.plot(*zip(*DWT_points), label=f\"DWT constant Q\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"MSE\")\n",
    "plt.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform quantization vs optimal quantization\n",
    "\n",
    "As we did with the DCT, let's compare both types of quantization in the RD space. Steps:\n",
    "\n",
    "1. Compute the RD slope of each subband for a set of quantization steps. For this we will suppose that the subbands are independent (the DWT is orthogonal), measuring the distortion in the wavelet domain.\n",
    "2. Sort the slopes. This will determine the optimal progression of quantization steps (which subband to incorporate more data to the code-stream, progressively).\n",
    "3. Compute the distortion in the image domain for each bit-rate. Notice that this information should match with the privided by the step 1 (measuring the distortion in the wavelet domain). However, we prefer to computate the distortion in the image domain because the transform does not need to be orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Read the image, move to the YUV domain, and compute the DWT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = read_image(test_image)\n",
    "x = YUV.from_RGB(xx.astype(np.int16) - 128)\n",
    "y = DWT.analyze(x, wavelet, N_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each subband, we populate:\n",
    "1. A list of RD points, and\n",
    "2. A list of RD slopes with these points, indicanting also the corresponding quantization step and subband.\n",
    "\n",
    "Remember that we have a RD point for each quantization step for each subband. The first dimension of these lists is indexed the subband, and the second dimension is indexed by the quantization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BPP=0, the MSE is the energy of the subband. No slope can be computed for the first point.\n",
    "RD_points = [[(0, information.energy(y[0]) / y[0].size)]] # Work with MSE's that are average distortions\n",
    "RD_slopes = [[]]\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        sb_avg_energy = information.energy(sb) / sb.size\n",
    "        # The first point of each RD curve has a maximum distortion equal\n",
    "        # to the energy of the subband and a rate = 0\n",
    "        RD_points.append([(0, sb_avg_energy)])\n",
    "        RD_slopes.append([])\n",
    "\n",
    "for i,j in enumerate(RD_points):\n",
    "    print(i,j)\n",
    "    \n",
    "for i,j in enumerate(RD_slopes):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now populate the rest of points of each subband\n",
    "\n",
    "# Subband LL\n",
    "sb_number = 0\n",
    "sb = y[0]\n",
    "Q_step_number = 0\n",
    "for Q_step in Q_steps:\n",
    "    print(Q_steps)\n",
    "    sb_k = Q.quantize(sb, Q_step)\n",
    "    sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "    sb_MSE = distortion.MSE(sb, sb_dQ)\n",
    "    sb_BPP = information.PNG_BPP((sb_k.astype(np.int32) + 32768).astype(np.uint16), \"/tmp/BPP_\")[0]\n",
    "    #sb_BPP = information.entropy(sb_k.astype(np.int16).flatten())\n",
    "    RD_points[sb_number].append((sb_BPP, sb_MSE))\n",
    "    delta_BPP = sb_BPP - RD_points[sb_number][Q_step_number][0]\n",
    "    delta_MSE = RD_points[sb_number][Q_step_number][1] - sb_MSE\n",
    "    if delta_BPP > 0:\n",
    "        slope = delta_MSE/delta_BPP\n",
    "    else:\n",
    "        slope = 0\n",
    "    RD_slopes[sb_number].append((Q_step, slope, (sb_number)))\n",
    "    Q_step_number += 1\n",
    "\n",
    "print(N_levels)\n",
    "    \n",
    "for i,j in enumerate(RD_points):\n",
    "    print(i, \"---\", j)\n",
    "    \n",
    "for i,j in enumerate(RD_slopes):\n",
    "    print(i, \"---\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_number = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        Q_step_number = 0\n",
    "        for Q_step in Q_steps:\n",
    "            sb_k = Q.quantize(sb, Q_step)\n",
    "            sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "            sb_MSE = distortion.MSE(sb, sb_dQ)\n",
    "            sb_BPP = information.PNG_BPP((sb_k.astype(np.int32) + 32768).astype(np.uint16), \"/tmp/BPP_\")[0]\n",
    "            #sb_BPP = information.entropy(sb_k.astype(np.int16).flatten())\n",
    "            RD_points[sb_number].append((sb_BPP, sb_MSE))\n",
    "            delta_BPP = sb_BPP - RD_points[sb_number][Q_step_number][0]\n",
    "            delta_MSE = RD_points[sb_number][Q_step_number][1] - sb_MSE\n",
    "            if delta_BPP > 0:\n",
    "                slope = delta_MSE/delta_BPP\n",
    "            else:\n",
    "                slope = 9^9\n",
    "            print(sb_number, len(y))\n",
    "            RD_slopes[sb_number].append((Q_step, slope, (sb_number)))\n",
    "            Q_step_number += 1\n",
    "        sb_number += 1\n",
    "        \n",
    "for i,j in enumerate(RD_points):\n",
    "    print(i, \"---\", j)\n",
    "    \n",
    "for i,j in enumerate(RD_slopes):\n",
    "    print(i, \"---\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sb_number < 12:\n",
    "    pylab.figure(dpi=150)\n",
    "    pylab.plot(*zip(*RD_points[0]), label=\"0\", marker=0)\n",
    "    sb_number = 1\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            pylab.plot(*zip(*RD_points[sb_number]), label=f\"{sb_number}\", marker=sb_number)\n",
    "            sb_number += 1\n",
    "    pylab.title(\"RD curves of the subbands\")\n",
    "    pylab.xlabel(\"Bits/Pixel\")\n",
    "    pylab.ylabel(\"MSE\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sb_number < 12:\n",
    "    pylab.figure(dpi=150)\n",
    "    pylab.plot(*zip(*RD_points[0]), label=\"0\", marker=0)\n",
    "    sb_number = 1\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            pylab.plot(*zip(*RD_points[sb_number]), label=f\"{sb_number}\", marker=sb_number)\n",
    "            sb_number += 1\n",
    "    pylab.title(\"RD curves of the subbands\")\n",
    "    pylab.xlabel(\"Bits/Pixel\")\n",
    "    pylab.ylabel(\"MSE\")\n",
    "    pylab.yscale(\"log\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_slopes_without_sb_index = []\n",
    "RD_slopes_without_sb_index.append([])\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        RD_slopes_without_sb_index.append([])\n",
    "for Q_step in range(len(Q_steps)):\n",
    "    RD_slopes_without_sb_index[0].append(RD_slopes[0][Q_step][0:2])\n",
    "sb_number = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        for Q_step in range(len(Q_steps)):\n",
    "            RD_slopes_without_sb_index[sb_number].append(RD_slopes[sb_number][Q_step][0:2])\n",
    "        sb_number += 1\n",
    "print(RD_slopes_without_sb_index[0])\n",
    "if sb_number < 12:\n",
    "    pylab.figure(dpi=150)\n",
    "    pylab.plot(*zip(*RD_slopes_without_sb_index[0]), label=\"0\", marker=0)\n",
    "    sb_number = 1\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            pylab.plot(*zip(*RD_slopes_without_sb_index[sb_number]), label=f\"{sb_number}\", marker=sb_number)\n",
    "            sb_number += 1\n",
    "    pylab.title(\"Slopes of the RD curves of the subbands\")\n",
    "    pylab.xlabel(\"Q_step\")\n",
    "    pylab.ylabel(\"Slope\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sb_number < 12:\n",
    "    pylab.figure(dpi=150)\n",
    "    pylab.plot(*zip(*RD_slopes_without_sb_index[0]), label=\"0\", marker=0)\n",
    "    sb_number = 1\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            pylab.plot(*zip(*RD_slopes_without_sb_index[sb_number]), label=f\"{sb_number}\", marker=sb_number)\n",
    "            sb_number += 1\n",
    "    pylab.title(\"Slopes of the RD curves of the subbands\")\n",
    "    pylab.xlabel(\"Q_step\")\n",
    "    pylab.ylabel(\"Slope\")\n",
    "    pylab.yscale(\"log\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the slopes of the curves are quite similar, but the LL subband is somewhat steeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = []\n",
    "for Q_step in range(len(Q_steps)):\n",
    "    single_list.append(tuple(RD_slopes[0][Q_step]))\n",
    "sb_number = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        for Q_step in range(len(Q_steps)):\n",
    "            single_list.append(tuple(RD_slopes[sb_number][Q_step]))\n",
    "        sb_number += 1\n",
    "sorted_slopes = sorted(single_list, key=lambda x: x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(decomposition, Q_steps):\n",
    "    #print(Q_steps)\n",
    "    LL = decomposition[0]\n",
    "    LL_k = Q.quantize(LL, Q_steps[0])\n",
    "    decomposition_k = [LL_k]\n",
    "    sb_number = 1\n",
    "    for sr in decomposition[1:]:\n",
    "        sr_k = []\n",
    "        for sb in sr:\n",
    "            #print(sb_number)\n",
    "            sb_k = Q.quantize(sb, Q_steps[sb_number])\n",
    "            sr_k.append(sb_k)\n",
    "            sb_number += 1\n",
    "        decomposition_k.append(tuple(sr_k))\n",
    "    return decomposition_k\n",
    "\n",
    "def dequantize(decomposition_k, Q_steps):\n",
    "    LL_k = decomposition_k[0]\n",
    "    LL_dQ = Q.dequantize(LL_k, Q_steps[0])\n",
    "    decomposition_dQ = [LL_dQ]\n",
    "    sb_number = 1\n",
    "    for sr_k in decomposition_k[1:]:\n",
    "        sr_dQ = []\n",
    "        for sb_k in sr_k:\n",
    "            sb_dQ = Q.dequantize(sb_k, Q_steps[sb_number])\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            sb_number += 1\n",
    "        decomposition_dQ.append(tuple(sr_dQ))\n",
    "    return decomposition_dQ\n",
    "\n",
    "def resolution_level(sb_number):\n",
    "    '''Resolution level in decomposition.'''\n",
    "    if sb_number > 0:\n",
    "        return ((sb_number - 1) // 3) + 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def subband_index(sb_number):\n",
    "    '''Subband index in resolution level.'''\n",
    "    if sb_number > 0:\n",
    "        return (sb_number % 3) - 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimal_RD_points = []\n",
    "#y_prog = DWT.analyze(np.zeros_like(x), wavelet, N_levels)\n",
    "#print(len(y_prog))\n",
    "Q_steps_by_subband = [9**9]\n",
    "#for sr in y_prog[1:]:\n",
    "for sr in y[1:]:\n",
    "    #print(len(sr))\n",
    "    for sb in sr:\n",
    "        Q_steps_by_subband.append(9**9)\n",
    "#print(Q_steps_by_subband)\n",
    "slope_index = 0\n",
    "for s in sorted_slopes:\n",
    "    sb_number = s[2]\n",
    "    #print(\"sb_number\", sb_number)\n",
    "    Q_steps_by_subband[sb_number] = s[0]\n",
    "    #print(sb_number, Q_steps_by_subband[sb_number])\n",
    "    #y_prog[resolution_level(sb_number)][subband_index(sb_number)] = y[resolution_level(sb_number)][subband_index(sb_number)]\n",
    "    #y_k = quantize(y_prog, Q_steps_by_subband)\n",
    "    y_k = quantize(y, Q_steps_by_subband)\n",
    "    BPP = (write_compact_decomposition(y_k, f\"/tmp/optimal_{slope_index}_\", 0)*8)/xx.size\n",
    "    #BPP = entropy(y_k)\n",
    "    slope_index += 1\n",
    "    y_dQ = dequantize(y_k, Q_steps_by_subband)\n",
    "    z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "    zz_dQ = np.clip(YUV.to_RGB(z_dQ), a_min=-128, a_max=127) + 128\n",
    "    MSE = distortion.MSE(xx, zz_dQ)\n",
    "    print(f\"{Q_steps_by_subband} {BPP} {MSE}\")\n",
    "    optimal_RD_points.append((BPP, MSE))\n",
    "    #image.show_RGB_image(zz_dQ, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_RD_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_points), label=\"Uniform quantization\")\n",
    "pylab.plot(*zip(*optimal_RD_points), label=\"Optimal quantization\")\n",
    "#pylab.plot(*zip(*JPEG_RD_points), label=\"JPEG\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"MSE\")\n",
    "plt.legend(loc=\"best\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTE PASO NO ES NECESARIO: Compute the average energy of the image and the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(decomposition):\n",
    "    accumulated_energy = information.energy(decomposition[0])\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            accumulated_energy += information.energy(sb)\n",
    "    return accumulated_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = read_image(test_image).astype(np.int16) - 128\n",
    "#xx = np.full(shape=(512, 512, 3), fill_value=100) - 128\n",
    "x = YUV.from_RGB(xx)\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "image_energy = information.average_energy(x)\n",
    "print(image_energy)\n",
    "print(energy(y)/x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform gains\n",
    "\n",
    "This information measures whether the transform amplifies or attenuates the signal. If the forward transform amplifies the signal, the energy of the decomposition will be larger than the energy of the original signal, and viceversa. The same idea can be applied to the inverse transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.full(shape=(512, 512, 3), fill_value=1)\n",
    "x_energy = information.energy(x)\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "decom_energy = information.energy(y[0])\n",
    "z = DWT.synthesize(y, wavelet, N_levels)\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        decom_energy += information.energy(sb)\n",
    "z_energy = information.energy(z)\n",
    "print(wavelet)\n",
    "print(\"Energy of the original image:\", x_energy)\n",
    "print(\"Energy of the decomposition:\", decom_energy)\n",
    "print(\"Energy of the reconstucted image:\", z_energy)\n",
    "print(\"Average energy of the original image\", x_energy / x.size)\n",
    "print(\"Average energy of the decomposition:\", decom_energy / x.size)\n",
    "print(\"Average energy of the reconstructed image:\", z_energy / x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the transform is energy preserving, which means that we the distortion generated by quantization is the same in the image and the wavelet domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subband gains\n",
    "\n",
    "All the wavelet transforms implemented by PyWavelets are unitary (preserve the energy). However, this not means that the subbands have the same gain. We can determine the subbands gain of the inverse transform giving a fixed amount of energy to each subband and computing the energy of the inverse transform of the decomposition. Finally, considering that the inverse transform has a gain of one, the gains are scaled to sum 1.\n",
    "\n",
    "We are specially interested in the subband gains, considering the inverse transform, because in the compression process the subbands are quantized, and the quantization error is scaled by the gain of the subbands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = []\n",
    "x = np.zeros(shape=(512, 512, 3))\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "coeff_value = y[0].size\n",
    "y[0][...] = coeff_value/y[0].size\n",
    "z = DWT.synthesize(y, wavelet, N_levels)\n",
    "gains.append(distortion.energy(z))\n",
    "prev_sb = y[0]\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        prev_sb[...] = 0.0\n",
    "        sb[...] = coeff_value/sb.size\n",
    "        z = DWT.synthesize(y, wavelet, N_levels)\n",
    "        gains.append(distortion.energy(z))\n",
    "        prev_sb = sb\n",
    "        \n",
    "x = np.empty(shape=(512, 512, 3))\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "coeff_value = y[0].size\n",
    "y[0][...] = coeff_value/y[0].size\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        sb[...] = coeff_value/sb.size\n",
    "z = DWT.synthesize(y, wavelet, N_levels)\n",
    "z_energy = distortion.energy(z)\n",
    "\n",
    "gains = [gain/z_energy for gain in gains]\n",
    "print(\"Unitary (normalized) inverse transform subband gains:\", gains)\n",
    "np.testing.assert_almost_equal(sum(gains), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD performance considering (and not) the subband gains\n",
    "\n",
    "We compute the RD cuve of using scalar quantization when:\n",
    "1. All subbands are quantized using the same quantization step.\n",
    "2. The quantization step used in a subband is divided by the subband gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = read_image(test_image).astype(np.int16) - 128\n",
    "x = YUV.from_RGB(xx)\n",
    "\n",
    "constant_Q_points = []\n",
    "for Q_step in Q_steps:\n",
    "    y = DWT.analyze(x, wavelet, N_levels)\n",
    "    LL = y[0]\n",
    "    LL_k = Q.quantize(LL, Q_step)\n",
    "    y_k = [LL_k]\n",
    "    LL_dQ = Q.dequantize(LL_k, Q_step)\n",
    "    y_dQ = [LL_dQ]\n",
    "    for sr in y[1:]:\n",
    "        sr_k = []\n",
    "        sr_dQ = []\n",
    "        for sb in sr:\n",
    "            sb_k = Q.quantize(sb, Q_step)\n",
    "            sr_k.append(sb_k)\n",
    "            sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "            sr_dQ.append(sb_dQ)\n",
    "        y_k.append(tuple(sr_k))\n",
    "        y_dQ.append(tuple(sr_dQ))\n",
    "    BPP = (write_compact_decomposition(y_k, f\"/tmp/constant_{Q_step}\", 0)*8)/x.size\n",
    "    z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "    zz_dQ = np.clip(YUV.to_RGB(z_dQ), a_min=-128, a_max=127)\n",
    "    MSE = distortion.MSE(xx, zz_dQ)\n",
    "    print(f\"{Q_step} {BPP} {MSE}\")\n",
    "    constant_Q_points.append((BPP, MSE))\n",
    "    #image.show_RGB_image(zz_dQ + 128, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that the slope of the subband is proportional to the subband gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = read_image(test_image).astype(np.int16) - 128\n",
    "x = YUV.from_RGB(xx)\n",
    "\n",
    "relative_gains = [gain/gains[-1] for gain in gains]\n",
    "print(relative_gains)\n",
    "gains_Q_points = []\n",
    "for Q_step in Q_steps:\n",
    "    y = DWT.analyze(x, wavelet, N_levels)[::-1]\n",
    "    counter = len(y) - 1\n",
    "    for sr in y[:-1]:\n",
    "        sr_k = []\n",
    "        sr_dQ = []\n",
    "        for sb in sr:\n",
    "            _Q_step = Q_step / relative_gains[counter]\n",
    "            print(\"Q_step =\",_Q_step)\n",
    "            sb_k = Q.quantize(sb, _Q_step)\n",
    "            sr_k.append(sb_k)\n",
    "            sb_dQ = Q.dequantize(sb_k, _Q_step)\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            counter -= 1\n",
    "        y_k.append(tuple(sr_k))\n",
    "        y_dQ.append(tuple(sr_dQ))\n",
    "    LL = y[-1]\n",
    "    _Q_step = Q_step / relative_gains[0]\n",
    "    print(_Q_step)\n",
    "    LL_k = Q.quantize(LL, _Q_step)\n",
    "    y_k = [LL_k]\n",
    "    LL_dQ = Q.dequantize(LL_k, _Q_step)\n",
    "    y_dQ = [LL_dQ]\n",
    "    BPP = (write_compact_decomposition(y_k, f\"/tmp/gains_{Q_step}\", 0)*8)/x.size\n",
    "    z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "    zz_dQ = np.clip(YUV.to_RGB(z_dQ), a_min=-128, a_max=127)\n",
    "    MSE = distortion.MSE(xx, zz_dQ)\n",
    "    print(f\"{Q_step} {BPP} {MSE}\")\n",
    "    gains_Q_points.append((BPP, MSE))\n",
    "    image.show_RGB_image(zz_dQ + 128, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*constant_Q_points), label=f\"Constant Q\")\n",
    "pylab.plot(*zip(*gains_Q_points), label=f\"Gains Q\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"MSE\")\n",
    "plt.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal quantization progression\n",
    "\n",
    "The previous quantization is not (usually) optimal, because the RD constribution of each subband is not constant.\n",
    "Let's use now a different quantization step for each subband that operates (approximately) at the same RD slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of uniform quantization\n",
    "\n",
    "We will measure also the distortion in both domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_step = 128\n",
    "x = read_image(test_image).astype(np.int16) #- 128\n",
    "#x = YUV.from_RGB(xx)\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "\n",
    "LL = y[0]\n",
    "LL_k = Q.quantize(LL, Q_step)\n",
    "LL_dQ = Q.dequantize(LL_k, Q_step)\n",
    "dist = distortion.MSE(LL, LL_dQ)\n",
    "subband_ratio = LL.size / x.size\n",
    "print(subband_ratio)\n",
    "MSE_wavelet_domain = dist * subband_ratio #* gains[0]\n",
    "counter = 1\n",
    "y_dQ = [LL_dQ]\n",
    "for sr in y[1:]:\n",
    "    sr_dQ = []\n",
    "    for sb in sr:\n",
    "        sb_k = Q.quantize(sb, Q_step)\n",
    "        sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "        sr_dQ.append(sb_dQ)\n",
    "        dist = distortion.MSE(sb, sb_dQ)\n",
    "        subband_ratio = sb.size / x.size\n",
    "        print(subband_ratio)\n",
    "        MSE_wavelet_domain += dist * subband_ratio #* gains[counter]\n",
    "        counter += 1\n",
    "    y_dQ.append(tuple(sr_dQ))\n",
    "\n",
    "z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "cz_dQ = np.clip(z_dQ, a_min=0, a_max=255)\n",
    "#zz_dQ = np.clip( YUV.to_RGB(z_dQ) + 128, a_min=0, a_max=255)\n",
    "#zz_dQ = YUV.to_RGB(z_dQ) #+ 128\n",
    "#print(\"Distortion in the image domain:\", distortion.MSE(xx + 128, zz_dQ))\n",
    "print(\"Distortion in the image domain:\", distortion.MSE(x, cz_dQ))\n",
    "print(\"Distortion in the wavelet domain:\", MSE_wavelet_domain)\n",
    "image.show_RGB_image(cz_dQ, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal quantization progression\n",
    "\n",
    "The previous quantization is not (usually) optimal, because the RD constribution of each subband is not constant.\n",
    "Let's use now a different quantization step for each subband that operates (approximately) at the same RD slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An orthogonality test\n",
    "\n",
    "Orthogonality is necessary to avoid that the quantization error generated in a subband does not affect to the rest of subband. This will speed up the RD optimization because the distortion can be measured in the DWT domain.\n",
    "\n",
    "This orthogonality test does:\n",
    "1. Compute the DWT of an image.\n",
    "2. Set to zero all the subbands except one.\n",
    "3. Compute the inverse DWT.\n",
    "4. Compute the DWT again of the previous reconstruction.\n",
    "5. Test if the decomposition matches the one generated in the step 2.  If matches (with some maximum error), the transform is orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "subband_to_keep = 5\n",
    "if subband_to_keep > DWT._N_levels:\n",
    "    print(\"No way, Jos√©\")\n",
    "y[0][...] = 0.0\n",
    "counter = 0\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        if counter != subband_to_keep:\n",
    "            sb[...] = 0.0\n",
    "        counter += 1\n",
    "z = DWT.synthesize(y, wavelet, N_levels)\n",
    "#image.show_RGB_image(z, \"Reconstructed image\")\n",
    "y2 = DWT.analyze(z, wavelet, N_levels)\n",
    "counter = 0\n",
    "orthogonal = True\n",
    "for sr, sr2 in zip(y[1:], y2[1:]):\n",
    "    for sb, sb2 in zip(sr, sr2):\n",
    "        #print((sb == sb2).allclose())\n",
    "        if not np.allclose(sb, sb2):\n",
    "            orthogonal = False\n",
    "        #if counter == subband_to_keep:\n",
    "        #    image.show_RGB_image(sb)\n",
    "        #    image.show_RGB_image(sb2)\n",
    "        counter += 1\n",
    "print(\"Orthogonal:\", orthogonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to know if the transform is orthogonal is compute the quantization distortion in the wavelet domain and see if it is the same than the distortion in the image domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal quantization progression\n",
    "\n",
    "The previous quantization is not (usually) optimal, because the RD constribution of each subband is not constant.\n",
    "Let's use now a different quantization step for each subband that operates (approximately) at the same RD slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information is important to known if the transform is unitary or not (usually, biorthogonal transforms are not unitary, i.e., the energy of the decomposition is different to (usually larger than) the energy of the image). Notice that if the transform is not unitary, the distortion is measured differently in the image and the transform domain. For example, is the gain is larger than 1, then overall distortion should be divided by the gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_image(test_image)\n",
    "#x = YUV.from_RGB(xx)\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "image_energy = distortion.energy(x)\n",
    "image_average_energy = image_energy / x.size\n",
    "print(\"Image average energy:\", image_average_energy)\n",
    "#decom_average_energy = distortion.average_energy(y[0])*y[0].size/x.size\n",
    "decom_energy = distortion.energy(y[0])\n",
    "counter = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        #decom_energy += distortion.average_energy(sb)*sb.size/x.size\n",
    "        decom_energy += distortion.energy(sb)\n",
    "        counter += 1\n",
    "print(\"Decomposition energy\", decom_energy)\n",
    "decom_average_energy = decom_energy / x.size\n",
    "print(\"Decomposition average energy\", decom_average_energy)\n",
    "forward_transform_gain = decom_energy/image_energy\n",
    "print(\"Forward transform gain:\", forward_transform_gain)\n",
    "print(\"The transform is\", end=' ')\n",
    "try:\n",
    "    np.testing.assert_almost_equal(forward_transform_gain, 1.0)\n",
    "except AssertionError:\n",
    "    print(\"not unitary\")\n",
    "else:\n",
    "    print(\"unitary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
